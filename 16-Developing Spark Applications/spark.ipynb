{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Spark Applications\n",
    "Spark applications are the combination of two things: a spark cluster and your code. In this case, the cluster will be local mode and the application will be the one that is pre-defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Python Applications\n",
    "To run an application, you simply execute the script against the cluster. To facilitate code reuse, it is common to package multiple python files into egg or Zip files of spark code. To include those files, you can use the --py files argument of spark-submit to add .py, .zip, or .egg files to be distributed with your application\n",
    "\n",
    "When running the application, we just need to call spark-submit with that information\n",
    "\n",
    "```\n",
    "$SPARK_HOME/bin/spark-submit --master local pyspark_template/main.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Spark Applications\n",
    "Testing spark applications relies on a couple of key principles and tactics that you should keep in mind as you're writing your applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategic Principles\n",
    "\n",
    "\n",
    "### Input Data Resilience\n",
    "Being resilient to different kinds of input data is something that is quite fundamental to how you write your data pipelines. The data will change because the business needs will change. Therefore your spark applications and pipelines should be resilient to at least some degree of change in the input data or otherwise ensure that these failures are handled\n",
    "\n",
    "### Business logic resilience and evolution\n",
    "You want to ensure that what you're deducing from the raw data is what you actually think that you're deducing.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('spark': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8bbc17edfc6fec1dafd662e4d54fee75495278ea7d904ef532688e2f0ecb6da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
